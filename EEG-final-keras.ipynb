{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from cached archive.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn; seaborn.set()\n",
    "from cesium import datasets\n",
    "\n",
    "# Returns\n",
    "#     dict\n",
    "#         Dictionary with attributes:\n",
    "#             - times: list of (4096,) arrays of time values\n",
    "#             - measurements: list of (4096,) arrays of measurement values\n",
    "#             - classes: array of class labels for each time series\n",
    "#             - archive: path to data archive\n",
    "#             - header: path to header file\n",
    "\n",
    "# https://github.com/cesium-ml/cesium-data/tree/master/andrzejak\n",
    "eeg = datasets.fetch_andrzejak()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group together classes (Z, O), (N, F), (S) as normal, interictal, ictal\n",
    "eeg[\"classes\"] = eeg[\"classes\"].astype(\"U16\") #  allocate memory for longer class names\n",
    "\n",
    "eeg[\"classes\"][np.logical_or(eeg[\"classes\"]==\"Z\", eeg[\"classes\"]==\"O\")] = \"Normal\"\n",
    "eeg[\"classes\"][np.logical_or(eeg[\"classes\"]==\"N\", eeg[\"classes\"]==\"F\")] = \"Interictal\"\n",
    "eeg[\"classes\"][eeg[\"classes\"]==\"S\"] = \"Ictal\"\n",
    "\n",
    "fig, ax = plt.subplots(1, len(np.unique(eeg[\"classes\"])), sharey=True)\n",
    "for label, subplot in zip(np.unique(eeg[\"classes\"]), ax):\n",
    "    i = np.where(eeg[\"classes\"] == label)[0][0]\n",
    "    subplot.plot(eeg[\"times\"][i], eeg[\"measurements\"][i])\n",
    "    subplot.set(xlabel=\"time (s)\", ylabel=\"signal\", title=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature       mean median amplitude maximum minimum        std      skew\n",
      "channel          0      0         0       0       0          0         0\n",
      "0        -4.132048   -4.0     143.5   141.0  -146.0  40.411000  0.032805\n",
      "1       -52.444716  -51.0     211.5   169.0  -254.0  48.812668 -0.092715\n",
      "2        12.705150   13.0     165.0   184.0  -146.0  47.144789 -0.004100\n",
      "3        -3.992433   -4.0     171.5   162.0  -181.0  47.072316  0.063678\n",
      "4       -17.999268  -18.0     170.0   152.0  -188.0  44.910958  0.142753\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from cesium import featurize\n",
    "features_to_use = [\"mean\",\n",
    "                   \"median\",\n",
    "                   \"amplitude\",\n",
    "                   \"maximum\",\n",
    "                   \"minimum\",\n",
    "                   \"std\",\n",
    "                   \"skew\"]\n",
    "                   \n",
    "fset_cesium = featurize.featurize_time_series(times=eeg[\"times\"],\n",
    "                                              values=eeg[\"measurements\"],\n",
    "                                              errors=None,\n",
    "                                              features_to_use=features_to_use)\n",
    "print(fset_cesium.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def mean_square_signal(t, m, e):\n",
    "    return np.mean(m ** 2)\n",
    "\n",
    "def abs_diffs_signal(t, m, e):\n",
    "    return np.sum(np.abs(np.diff(m)))\n",
    "\n",
    "def variance(t, m, e):\n",
    "    return np.var(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature  mean_square abs_diffs     variance\n",
      "channel            0         0            0\n",
      "0        1650.122773   46948.0  1633.048953\n",
      "1        5133.124725   61118.0  2382.676526\n",
      "2        2384.051989   51269.0  2222.631150\n",
      "3        2231.742495   75014.0  2215.802969\n",
      "4        2340.967781   52873.0  2016.994142\n"
     ]
    }
   ],
   "source": [
    "other_features = {\n",
    "    \"mean_square\": mean_square_signal,\n",
    "    \"abs_diffs\": abs_diffs_signal,\n",
    "    \"variance\": variance\n",
    "}\n",
    "\n",
    "fset_others = featurize.featurize_time_series(times=eeg[\"times\"], values=eeg[\"measurements\"],\n",
    "                                           errors=None,\n",
    "                                           features_to_use=list(other_features.keys()),\n",
    "                                           custom_functions=other_features)\n",
    "print(fset_others.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "      <th>mean_square</th>\n",
       "      <th>abs_diffs</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.132048</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>143.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>-146.0</td>\n",
       "      <td>40.411000</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>1650.122773</td>\n",
       "      <td>46948.0</td>\n",
       "      <td>1633.048953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-52.444716</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>211.5</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-254.0</td>\n",
       "      <td>48.812668</td>\n",
       "      <td>-0.092715</td>\n",
       "      <td>5133.124725</td>\n",
       "      <td>61118.0</td>\n",
       "      <td>2382.676526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.705150</td>\n",
       "      <td>13.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-146.0</td>\n",
       "      <td>47.144789</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>2384.051989</td>\n",
       "      <td>51269.0</td>\n",
       "      <td>2222.631150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.992433</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>171.5</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>47.072316</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>2231.742495</td>\n",
       "      <td>75014.0</td>\n",
       "      <td>2215.802969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.999268</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>44.910958</td>\n",
       "      <td>0.142753</td>\n",
       "      <td>2340.967781</td>\n",
       "      <td>52873.0</td>\n",
       "      <td>2016.994142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature       mean median amplitude maximum minimum        std      skew  \\\n",
       "channel          0      0         0       0       0          0         0   \n",
       "0        -4.132048   -4.0     143.5   141.0  -146.0  40.411000  0.032805   \n",
       "1       -52.444716  -51.0     211.5   169.0  -254.0  48.812668 -0.092715   \n",
       "2        12.705150   13.0     165.0   184.0  -146.0  47.144789 -0.004100   \n",
       "3        -3.992433   -4.0     171.5   162.0  -181.0  47.072316  0.063678   \n",
       "4       -17.999268  -18.0     170.0   152.0  -188.0  44.910958  0.142753   \n",
       "\n",
       "feature  mean_square abs_diffs     variance  \n",
       "channel            0         0            0  \n",
       "0        1650.122773   46948.0  1633.048953  \n",
       "1        5133.124725   61118.0  2382.676526  \n",
       "2        2384.051989   51269.0  2222.631150  \n",
       "3        2231.742495   75014.0  2215.802969  \n",
       "4        2340.967781   52873.0  2016.994142  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fset_all = pd.concat([fset_cesium, fset_others], axis=1, sort=False)\n",
    "fset_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "      <th>mean_square</th>\n",
       "      <th>abs_diffs</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>channel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659069</td>\n",
       "      <td>0.124352</td>\n",
       "      <td>0.166760</td>\n",
       "      <td>-0.073713</td>\n",
       "      <td>0.123375</td>\n",
       "      <td>-0.046787</td>\n",
       "      <td>0.127373</td>\n",
       "      <td>0.113178</td>\n",
       "      <td>0.136089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <th>0</th>\n",
       "      <td>0.659069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220845</td>\n",
       "      <td>0.090440</td>\n",
       "      <td>-0.332449</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>-0.518063</td>\n",
       "      <td>0.282635</td>\n",
       "      <td>0.299343</td>\n",
       "      <td>0.287812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amplitude</th>\n",
       "      <th>0</th>\n",
       "      <td>0.124352</td>\n",
       "      <td>0.220845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962284</td>\n",
       "      <td>-0.963831</td>\n",
       "      <td>0.977369</td>\n",
       "      <td>-0.020502</td>\n",
       "      <td>0.928803</td>\n",
       "      <td>0.919876</td>\n",
       "      <td>0.928998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum</th>\n",
       "      <th>0</th>\n",
       "      <td>0.166760</td>\n",
       "      <td>0.090440</td>\n",
       "      <td>0.962284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.854975</td>\n",
       "      <td>0.929628</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.862968</td>\n",
       "      <td>0.848549</td>\n",
       "      <td>0.863782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.073713</td>\n",
       "      <td>-0.332449</td>\n",
       "      <td>-0.963831</td>\n",
       "      <td>-0.854975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.952675</td>\n",
       "      <td>0.236293</td>\n",
       "      <td>-0.925386</td>\n",
       "      <td>-0.922492</td>\n",
       "      <td>-0.924960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature                mean    median amplitude   maximum   minimum       std  \\\n",
       "channel                   0         0         0         0         0         0   \n",
       "feature   channel                                                               \n",
       "mean      0        1.000000  0.659069  0.124352  0.166760 -0.073713  0.123375   \n",
       "median    0        0.659069  1.000000  0.220845  0.090440 -0.332449  0.236200   \n",
       "amplitude 0        0.124352  0.220845  1.000000  0.962284 -0.963831  0.977369   \n",
       "maximum   0        0.166760  0.090440  0.962284  1.000000 -0.854975  0.929628   \n",
       "minimum   0       -0.073713 -0.332449 -0.963831 -0.854975  1.000000 -0.952675   \n",
       "\n",
       "feature                skew mean_square abs_diffs  variance  \n",
       "channel                   0           0         0         0  \n",
       "feature   channel                                            \n",
       "mean      0       -0.046787    0.127373  0.113178  0.136089  \n",
       "median    0       -0.518063    0.282635  0.299343  0.287812  \n",
       "amplitude 0       -0.020502    0.928803  0.919876  0.928998  \n",
       "maximum   0        0.201300    0.862968  0.848549  0.863782  \n",
       "minimum   0        0.236293   -0.925386 -0.922492 -0.924960  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = fset_all.corr()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_features(threshold): \n",
    "    corr_matrix_abs = corr_matrix.abs()\n",
    "\n",
    "    # List of all features\n",
    "    all_features = [x[0] for x in corr_matrix]\n",
    "    \n",
    "    # List all values with high correlation\n",
    "    high_corr_var = np.where(corr_matrix_abs > threshold)\n",
    "    high_corr_var = [(corr_matrix_abs.columns[x][0],corr_matrix_abs.columns[y][0]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "\n",
    "    # Create list of unique first, second tuple\n",
    "    a = [x[0] for x in high_corr_var]\n",
    "    b = [x[1] for x in high_corr_var]\n",
    "\n",
    "    first = list(set(a))\n",
    "    second = list(set(b))\n",
    "\n",
    "    # Subtract second tuple from first to get list of features that have low or no correlation\n",
    "    low_corr = list(set(a) - set(b))\n",
    "\n",
    "    # Check if there was any features not included from the complete list\n",
    "    other_features = list(set(all_features) - set(a))\n",
    "\n",
    "    final_features = low_corr + other_features\n",
    "    return(final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 =  ['amplitude', 'mean', 'variance', 'skew']\n",
      "Threshold: 0.6 =  ['amplitude', 'mean', 'variance', 'skew', 'median']\n",
      "Threshold: 0.75 =  ['amplitude', 'variance', 'skew', 'mean', 'median']\n"
     ]
    }
   ],
   "source": [
    "features_5 = get_final_features(0.5)\n",
    "features_6 = get_final_features(0.6)\n",
    "features_75 = get_final_features(0.75)\n",
    "\n",
    "print(\"Threshold: 0.5 = \", features_5)\n",
    "print(\"Threshold: 0.6 = \", features_6)\n",
    "print(\"Threshold: 0.75 = \", features_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframes with just the features we want\n",
    "fset_5 = fset_all[features_5]\n",
    "fset_6 = fset_all[features_6]\n",
    "fset_75 = fset_all[features_75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_model(fset):\n",
    "    models = []\n",
    "    train, test = train_test_split(np.arange(len(eeg[\"classes\"])), random_state=0)\n",
    "    \n",
    "    model_lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(fset.iloc[train], eeg[\"classes\"][train])\n",
    "    \n",
    "    model_nb = GaussianNB().fit(fset.iloc[train], eeg[\"classes\"][train])\n",
    "    \n",
    "    model_knn = KNeighborsClassifier(3).fit(fset.iloc[train], eeg[\"classes\"][train])\n",
    "\n",
    "    model_rfc = RandomForestClassifier(n_estimators=128, max_features=\"auto\", random_state=0).fit(fset.iloc[train], eeg[\"classes\"][train])\n",
    "\n",
    "    models = [model_lr, model_nb, model_knn, model_rfc]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = build_model(fset_5)\n",
    "model_6 = build_model(fset_6)\n",
    "model_75 = build_model(fset_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "    \n",
    "def predict(fset, model):\n",
    "    preds_lr = model[0].predict(fset)\n",
    "    preds_nb = model[1].predict(fset)\n",
    "    preds_knn = model[2].predict(fset)\n",
    "    preds_rfc = model[3].predict(fset)\n",
    "    \n",
    "    print(\"\\nLogistic Regression: \")\n",
    "    print(\"confusion_matrix:\\n\", confusion_matrix(preds_lr[test], eeg[\"classes\"][test], labels=[\"Normal\", \"Interictal\", \"Ictal\"]))\n",
    "    print(\"training accuracy = {:.2%}, test accuracy = {:.2%}\".format(\n",
    "              accuracy_score(preds_lr[train], eeg[\"classes\"][train]),\n",
    "              accuracy_score(preds_lr[test], eeg[\"classes\"][test])))\n",
    "    print(\"training precision = {:.2%}, test precision = {:.2%}\".format(\n",
    "              precision_score(preds_lr[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              precision_score(preds_lr[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training sensitivity = {:.2%}, test sensitivity = {:.2%}\".format(\n",
    "              recall_score(preds_lr[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              recall_score(preds_lr[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training f1_score = {:.2%}, test f1_score = {:.2%}\".format(\n",
    "              f1_score(preds_lr[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              f1_score(preds_lr[test], eeg[\"classes\"][test], average='weighted')))\n",
    "   \n",
    "    print(\"\\nNaive Bayes: \")\n",
    "    print(\"confusion_matrix:\\n\", confusion_matrix(preds_nb[test], eeg[\"classes\"][test], labels=[\"Normal\", \"Interictal\", \"Ictal\"]))\n",
    "    print(\"training accuracy = {:.2%}, test accuracy = {:.2%}\".format(\n",
    "              accuracy_score(preds_nb[train], eeg[\"classes\"][train]),\n",
    "              accuracy_score(preds_nb[test], eeg[\"classes\"][test])))\n",
    "    print(\"training precision = {:.2%}, test precision = {:.2%}\".format(\n",
    "              precision_score(preds_nb[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              precision_score(preds_nb[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training sensitivity = {:.2%}, test sensitivity = {:.2%}\".format(\n",
    "              recall_score(preds_nb[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              recall_score(preds_nb[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training f1_score = {:.2%}, test f1_score = {:.2%}\".format(\n",
    "              f1_score(preds_nb[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              f1_score(preds_nb[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    \n",
    "    print(\"\\nK-nearest Neighbors: \")\n",
    "    print(\"confusion_matrix:\\n\", confusion_matrix(preds_knn[test], eeg[\"classes\"][test], labels=[\"Normal\", \"Interictal\", \"Ictal\"]))\n",
    "    print(\"training accuracy = {:.2%}, test accuracy = {:.2%}\".format(\n",
    "              accuracy_score(preds_knn[train], eeg[\"classes\"][train]),\n",
    "              accuracy_score(preds_knn[test], eeg[\"classes\"][test])))\n",
    "    print(\"training precision = {:.2%}, test precision = {:.2%}\".format(\n",
    "              precision_score(preds_knn[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              precision_score(preds_knn[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training sensitivity = {:.2%}, test sensitivity = {:.2%}\".format(\n",
    "              recall_score(preds_knn[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              recall_score(preds_knn[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training f1_score = {:.2%}, test f1_score = {:.2%}\".format(\n",
    "              f1_score(preds_knn[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              f1_score(preds_knn[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    \n",
    "    print(\"\\nRandom Forest Classifier: \")\n",
    "    print(\"confusion_matrix:\\n\", confusion_matrix(preds_rfc[test], eeg[\"classes\"][test], labels=[\"Normal\", \"Interictal\", \"Ictal\"]))\n",
    "    print(\"training accuracy = {:.2%}, test accuracy = {:.2%}\".format(\n",
    "              accuracy_score(preds_rfc[train], eeg[\"classes\"][train]),\n",
    "              accuracy_score(preds_rfc[test], eeg[\"classes\"][test])))\n",
    "    print(\"training precision = {:.2%}, test precision = {:.2%}\".format(\n",
    "              precision_score(preds_rfc[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              precision_score(preds_rfc[test], eeg[\"classes\"][test], average='weighted')))\n",
    "    print(\"training sensitivity = {:.2%}, test sensitivity = {:.2%}\".format(\n",
    "              recall_score(preds_rfc[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              recall_score(preds_rfc[test], eeg[\"classes\"][test], average='weighted'))),\n",
    "    print(\"training f1_score = {:.2%}, test f1_score = {:.2%}\".format(\n",
    "              f1_score(preds_rfc[train], eeg[\"classes\"][train], average='weighted'),\n",
    "              f1_score(preds_rfc[test], eeg[\"classes\"][test], average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression: \n",
      "confusion_matrix:\n",
      " [[37 26  1]\n",
      " [10 25  3]\n",
      " [ 0  3 20]]\n",
      "training accuracy = 61.33%, test accuracy = 65.60%\n",
      "training precision = 66.41%, test precision = 69.71%\n",
      "training sensitivity = 61.33%, test sensitivity = 65.60%\n",
      "training f1_score = 62.41%, test f1_score = 66.31%\n",
      "\n",
      "Naive Bayes: \n",
      "confusion_matrix:\n",
      " [[46 44  0]\n",
      " [ 1  8  7]\n",
      " [ 0  2 17]]\n",
      "training accuracy = 55.20%, test accuracy = 56.80%\n",
      "training precision = 78.01%, test precision = 83.13%\n",
      "training sensitivity = 55.20%, test sensitivity = 56.80%\n",
      "training f1_score = 61.91%, test f1_score = 63.29%\n",
      "\n",
      "K-nearest Neighbors: \n",
      "confusion_matrix:\n",
      " [[25 28  2]\n",
      " [22 22  2]\n",
      " [ 0  4 20]]\n",
      "training accuracy = 80.53%, test accuracy = 53.60%\n",
      "training precision = 81.13%, test precision = 54.40%\n",
      "training sensitivity = 80.53%, test sensitivity = 53.60%\n",
      "training f1_score = 80.74%, test f1_score = 53.76%\n",
      "\n",
      "Random Forest Classifier: \n",
      "confusion_matrix:\n",
      " [[31  6  1]\n",
      " [16 46  2]\n",
      " [ 0  2 21]]\n",
      "training accuracy = 100.00%, test accuracy = 78.40%\n",
      "training precision = 100.00%, test precision = 79.77%\n",
      "training sensitivity = 100.00%, test sensitivity = 78.40%\n",
      "training f1_score = 100.00%, test f1_score = 78.54%\n"
     ]
    }
   ],
   "source": [
    "predict(fset_5, model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression: \n",
      "confusion_matrix:\n",
      " [[45 45  0]\n",
      " [ 2  8  4]\n",
      " [ 0  1 20]]\n",
      "training accuracy = 57.07%, test accuracy = 58.40%\n",
      "training precision = 76.61%, test precision = 84.60%\n",
      "training sensitivity = 57.07%, test sensitivity = 58.40%\n",
      "training f1_score = 62.47%, test f1_score = 64.87%\n",
      "\n",
      "Naive Bayes: \n",
      "confusion_matrix:\n",
      " [[46 44  0]\n",
      " [ 1  9  6]\n",
      " [ 0  1 18]]\n",
      "training accuracy = 54.67%, test accuracy = 58.40%\n",
      "training precision = 77.26%, test precision = 84.00%\n",
      "training sensitivity = 54.67%, test sensitivity = 58.40%\n",
      "training f1_score = 61.25%, test f1_score = 64.37%\n",
      "\n",
      "K-nearest Neighbors: \n",
      "confusion_matrix:\n",
      " [[24 27  2]\n",
      " [23 23  2]\n",
      " [ 0  4 20]]\n",
      "training accuracy = 79.73%, test accuracy = 53.60%\n",
      "training precision = 80.39%, test precision = 54.01%\n",
      "training sensitivity = 79.73%, test sensitivity = 53.60%\n",
      "training f1_score = 79.96%, test f1_score = 53.67%\n",
      "\n",
      "Random Forest Classifier: \n",
      "confusion_matrix:\n",
      " [[33  6  1]\n",
      " [14 44  2]\n",
      " [ 0  4 21]]\n",
      "training accuracy = 100.00%, test accuracy = 78.40%\n",
      "training precision = 100.00%, test precision = 79.08%\n",
      "training sensitivity = 100.00%, test sensitivity = 78.40%\n",
      "training f1_score = 100.00%, test f1_score = 78.47%\n"
     ]
    }
   ],
   "source": [
    "predict(fset_6, model_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression: \n",
      "confusion_matrix:\n",
      " [[45 45  0]\n",
      " [ 2  8  4]\n",
      " [ 0  1 20]]\n",
      "training accuracy = 57.07%, test accuracy = 58.40%\n",
      "training precision = 76.61%, test precision = 84.60%\n",
      "training sensitivity = 57.07%, test sensitivity = 58.40%\n",
      "training f1_score = 62.47%, test f1_score = 64.87%\n",
      "\n",
      "Naive Bayes: \n",
      "confusion_matrix:\n",
      " [[46 44  0]\n",
      " [ 1  9  6]\n",
      " [ 0  1 18]]\n",
      "training accuracy = 54.67%, test accuracy = 58.40%\n",
      "training precision = 77.26%, test precision = 84.00%\n",
      "training sensitivity = 54.67%, test sensitivity = 58.40%\n",
      "training f1_score = 61.25%, test f1_score = 64.37%\n",
      "\n",
      "K-nearest Neighbors: \n",
      "confusion_matrix:\n",
      " [[24 27  2]\n",
      " [23 23  2]\n",
      " [ 0  4 20]]\n",
      "training accuracy = 79.73%, test accuracy = 53.60%\n",
      "training precision = 80.39%, test precision = 54.01%\n",
      "training sensitivity = 79.73%, test sensitivity = 53.60%\n",
      "training f1_score = 79.96%, test f1_score = 53.67%\n",
      "\n",
      "Random Forest Classifier: \n",
      "confusion_matrix:\n",
      " [[34  7  1]\n",
      " [13 43  2]\n",
      " [ 0  4 21]]\n",
      "training accuracy = 100.00%, test accuracy = 78.40%\n",
      "training precision = 100.00%, test precision = 78.75%\n",
      "training sensitivity = 100.00%, test sensitivity = 78.40%\n",
      "training f1_score = 100.00%, test f1_score = 78.44%\n"
     ]
    }
   ],
   "source": [
    "predict(fset_75, model_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.5</td>\n",
       "      <td>-4.132048</td>\n",
       "      <td>1633.048953</td>\n",
       "      <td>0.032805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211.5</td>\n",
       "      <td>-52.444716</td>\n",
       "      <td>2382.676526</td>\n",
       "      <td>-0.092715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165.0</td>\n",
       "      <td>12.705150</td>\n",
       "      <td>2222.631150</td>\n",
       "      <td>-0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.5</td>\n",
       "      <td>-3.992433</td>\n",
       "      <td>2215.802969</td>\n",
       "      <td>0.063678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.0</td>\n",
       "      <td>-17.999268</td>\n",
       "      <td>2016.994142</td>\n",
       "      <td>0.142753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "feature amplitude       mean     variance      skew\n",
       "channel         0          0            0         0\n",
       "0           143.5  -4.132048  1633.048953  0.032805\n",
       "1           211.5 -52.444716  2382.676526 -0.092715\n",
       "2           165.0  12.705150  2222.631150 -0.004100\n",
       "3           171.5  -3.992433  2215.802969  0.063678\n",
       "4           170.0 -17.999268  2016.994142  0.142753"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fset_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(eeg[\"measurements\"], eeg[\"classes\"], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.reshape(X_train, (400,4097))\n",
    "X_test = np.reshape(X_test, (100,4097))\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y_train)\n",
    "integer_encoded_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "onehot_encoded_test = onehot_encoder.fit_transform(integer_encoded_test)\n",
    "\n",
    "y_train = onehot_encoded\n",
    "y_train = np.reshape(y_train, (400, 1, 3))\n",
    "\n",
    "y_test = onehot_encoded_test\n",
    "y_test = np.reshape(y_test, (100, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, None, 32)          192       \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, None, 32)          5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, None, 1000)        33000     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, None, 3)           3003      \n",
      "=================================================================\n",
      "Total params: 41,347\n",
      "Trainable params: 41,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=5, input_shape=(None,1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2 ))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2000 into shape (100,4097)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-324-49e2dd61e120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfset_5_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfset_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfset_5_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4097\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfset_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    277\u001b[0m            [5, 6]])\n\u001b[1;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2000 into shape (100,4097)"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 400\n",
    "EPOCHS = 300\n",
    "\n",
    "fset_5_array = fset_5.values\n",
    "X_train_final = np.reshape(fset_5_array, (100,4097))\n",
    "\n",
    "model.fit(fset_5.iloc[X_train[0]], y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5301502513885498, 0.7700342297554016]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 90, 254, 283, 445, 461,  15, 316, 489, 159, 153, 241, 250, 390,\n",
       "       289, 171, 329, 468, 355, 154,  37, 205, 366, 240, 108,  45, 438,\n",
       "        21, 367,  96, 233, 428, 118, 124, 191, 374, 492, 311, 451, 353,\n",
       "       238, 322,  46, 403, 221,  76,   1, 213, 325, 418, 102, 363, 170,\n",
       "       343, 144, 132,  12, 327, 173, 224, 342,  78, 276, 387, 425, 301,\n",
       "       196,  10, 469, 271,  75, 142,  65, 340, 484, 175, 362, 264, 100,\n",
       "       491, 295, 300, 235, 475, 219, 330, 326, 421, 157, 348,  54, 220,\n",
       "       402, 379, 200, 179, 372,  56, 440,  60, 208, 107, 336,  71, 474,\n",
       "         6, 412, 113, 236, 299, 155, 272,   7, 137,   8, 463, 432, 375,\n",
       "       284, 210, 188, 430,  49, 134, 365, 413])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-24.],\n",
       "        [-15.],\n",
       "        [ -5.],\n",
       "        ...,\n",
       "        [-57.],\n",
       "        [-54.],\n",
       "        [-30.]],\n",
       "\n",
       "       [[-48.],\n",
       "        [-52.],\n",
       "        [-63.],\n",
       "        ...,\n",
       "        [ -5.],\n",
       "        [ -9.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[ 49.],\n",
       "        [ 54.],\n",
       "        [ 62.],\n",
       "        ...,\n",
       "        [ 12.],\n",
       "        [ 13.],\n",
       "        [ 40.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 39.],\n",
       "        [ 41.],\n",
       "        [ 43.],\n",
       "        ...,\n",
       "        [-29.],\n",
       "        [-16.],\n",
       "        [  1.]],\n",
       "\n",
       "       [[249.],\n",
       "        [218.],\n",
       "        [176.],\n",
       "        ...,\n",
       "        [367.],\n",
       "        [299.],\n",
       "        [ 26.]],\n",
       "\n",
       "       [[ 34.],\n",
       "        [ 34.],\n",
       "        [ 31.],\n",
       "        ...,\n",
       "        [ -7.],\n",
       "        [-20.],\n",
       "        [ 91.]]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature amplitude       mean       variance      skew\n",
      "channel         0          0              0         0\n",
      "90          144.5 -28.239688    1987.303058 -0.046706\n",
      "254          99.0  -8.651452     916.789913 -0.347122\n",
      "283         254.0 -52.632170    4541.735582 -0.054374\n",
      "445         450.0   6.621186   20847.731531 -0.299523\n",
      "461         246.0  -7.891140   11268.679387  0.303489\n",
      "15          184.0   5.012692    2220.598814 -0.195767\n",
      "316         114.5  -3.758848    1391.233034 -0.257820\n",
      "489         945.5   3.282158   67213.825195  0.216552\n",
      "159         342.0 -19.309007    9676.057310  0.134387\n",
      "153         141.5  56.330242    1522.331019  0.182110\n",
      "241          65.5  -8.377593     346.218419 -0.317217\n",
      "250         405.5   0.377105    9239.074047  0.116386\n",
      "390         275.0   5.626312    7764.221353 -0.061711\n",
      "289          92.5  -3.938492     517.421650 -0.434865\n",
      "171         151.0   2.873810    1704.686785 -0.007218\n",
      "329         528.5 -38.859409   20723.485726  2.307538\n",
      "468         335.5 -53.463754   11322.854984  1.107440\n",
      "355         128.5  10.959727    1522.550245 -0.055996\n",
      "154         240.0   6.600928    4445.854166  0.202806\n",
      "37           77.5 -75.103734     534.277499  0.076754\n",
      "205         234.0  -3.262631    4914.709643  0.185728\n",
      "366         182.5 -15.857701    2365.160859  0.000418\n",
      "240         302.0  -7.396144    4750.624862 -0.271712\n",
      "108         203.5  -2.998291    3858.252621 -0.087986\n",
      "45          156.0 -18.813522    1575.992075  0.050949\n",
      "438        1012.0 -15.138882   85706.248469  0.489576\n",
      "21          104.5  -5.378570     865.928201  0.009344\n",
      "367         116.5  28.355138    1170.525329 -0.058368\n",
      "96          149.5  -3.159873    1699.131629 -0.188527\n",
      "233         102.5 -11.803271     804.132642 -0.273388\n",
      "..            ...        ...            ...       ...\n",
      "372         608.0 -30.079326   34623.541913  0.217686\n",
      "56          176.5   1.610935    2480.139085  0.073890\n",
      "440        1409.5  -8.122529  243626.097752 -1.580058\n",
      "60           75.5 -75.503783     511.163825 -0.071865\n",
      "208         293.5 -37.617525    5558.248880 -0.029854\n",
      "107         216.5   9.191848    4411.932440  0.049315\n",
      "336         178.5  23.210398    2277.455367 -0.025972\n",
      "71          153.5   6.471809    2042.409811  0.046354\n",
      "474         592.5   2.630705   49571.411827  0.192447\n",
      "6           162.0 -13.334635    2139.935127  0.003179\n",
      "412         470.0 -16.205760   34219.651829 -0.420786\n",
      "113         241.0   6.122773    4198.850682  0.026963\n",
      "236         184.5  -8.330242    2392.659552 -0.060674\n",
      "299         163.0  -6.296803    2604.640734 -0.187975\n",
      "155         262.0 -50.904564    5768.750716  0.343450\n",
      "272          86.5  -6.214791     351.634119 -0.279301\n",
      "7           126.5  -5.653893    1046.012990 -0.023597\n",
      "137         208.0  -3.186478    3622.324513  0.055949\n",
      "8           105.0   8.200879     990.880077 -0.002426\n",
      "463        1609.0  -5.442763  349235.628711 -1.256881\n",
      "432        1711.5 -10.084696  309876.509058 -1.043538\n",
      "375         736.0 -51.764706   50007.440853  2.661113\n",
      "284         157.0  28.515743    1934.321512 -1.223013\n",
      "210         112.5 -12.512326     965.169545 -0.260101\n",
      "188         195.5  -1.548206    2117.883995  0.128147\n",
      "430         527.5 -67.334147   35170.534916  0.425622\n",
      "49          184.5   3.820356    2488.566703 -0.055685\n",
      "134         196.0   2.203320    3293.202254  0.114851\n",
      "365         182.0 -16.297779    2961.872275 -0.952198\n",
      "413         948.0  25.535026  140352.575842 -0.864777\n",
      "\n",
      "[125 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fset_5.iloc[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(eeg[\"measurements\"], eeg[\"classes\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (4097,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-24., -15.,  -5., ..., -36., -33., -32.],\n",
       "       [-31., -37., -52., ..., 112., 118., 118.],\n",
       "       [116., 118., 120., ...,  28.,  27.,  31.],\n",
       "       ...,\n",
       "       [ 18.,  30.,  17., ..., -29., -43., -53.],\n",
       "       [-65., -75., -71., ..., -61., -44., -27.],\n",
       "       [-11.,  -5.,  -7., ...,  -7., -20.,  91.]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 90, 254, 283, 445, 461,  15, 316, 489, 159, 153, 241, 250, 390,\n",
       "       289, 171, 329, 468, 355, 154,  37, 205, 366, 240, 108,  45, 438,\n",
       "        21, 367,  96, 233, 428, 118, 124, 191, 374, 492, 311, 451, 353,\n",
       "       238, 322,  46, 403, 221,  76,   1, 213, 325, 418, 102, 363, 170,\n",
       "       343, 144, 132,  12, 327, 173, 224, 342,  78, 276, 387, 425, 301,\n",
       "       196,  10, 469, 271,  75, 142,  65, 340, 484, 175, 362, 264, 100,\n",
       "       491, 295, 300, 235, 475, 219, 330, 326, 421, 157, 348,  54, 220,\n",
       "       402, 379, 200, 179, 372,  56, 440,  60, 208, 107, 336,  71, 474,\n",
       "         6, 412, 113, 236, 299, 155, 272,   7, 137,   8, 463, 432, 375,\n",
       "       284, 210, 188, 430,  49, 134, 365, 413])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>984.5</td>\n",
       "      <td>-33.119112</td>\n",
       "      <td>86099.876952</td>\n",
       "      <td>-0.049577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>590.5</td>\n",
       "      <td>-5.672687</td>\n",
       "      <td>45599.431797</td>\n",
       "      <td>0.288864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>876.5</td>\n",
       "      <td>12.870393</td>\n",
       "      <td>110526.604876</td>\n",
       "      <td>-0.472757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1396.0</td>\n",
       "      <td>47.100073</td>\n",
       "      <td>228947.748833</td>\n",
       "      <td>-1.347758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.0</td>\n",
       "      <td>-17.999268</td>\n",
       "      <td>2016.994142</td>\n",
       "      <td>0.142753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.5</td>\n",
       "      <td>-3.992433</td>\n",
       "      <td>2215.802969</td>\n",
       "      <td>0.063678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>162.0</td>\n",
       "      <td>-13.334635</td>\n",
       "      <td>2139.935127</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.5</td>\n",
       "      <td>-13.600195</td>\n",
       "      <td>1475.830881</td>\n",
       "      <td>-0.120190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>138.5</td>\n",
       "      <td>-14.408348</td>\n",
       "      <td>1567.651900</td>\n",
       "      <td>-0.091485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>126.5</td>\n",
       "      <td>-5.653893</td>\n",
       "      <td>1046.012990</td>\n",
       "      <td>-0.023597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.0</td>\n",
       "      <td>8.200879</td>\n",
       "      <td>990.880077</td>\n",
       "      <td>-0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>109.0</td>\n",
       "      <td>7.406395</td>\n",
       "      <td>1063.600769</td>\n",
       "      <td>0.005112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.5</td>\n",
       "      <td>-13.600195</td>\n",
       "      <td>1475.830881</td>\n",
       "      <td>-0.120190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.5</td>\n",
       "      <td>-13.600195</td>\n",
       "      <td>1475.830881</td>\n",
       "      <td>-0.120190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151.5</td>\n",
       "      <td>-27.823041</td>\n",
       "      <td>2027.044839</td>\n",
       "      <td>0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1396.0</td>\n",
       "      <td>47.100073</td>\n",
       "      <td>228947.748833</td>\n",
       "      <td>-1.347758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>945.5</td>\n",
       "      <td>3.282158</td>\n",
       "      <td>67213.825195</td>\n",
       "      <td>0.216552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>-21.550891</td>\n",
       "      <td>291865.435597</td>\n",
       "      <td>0.180866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>984.5</td>\n",
       "      <td>-33.119112</td>\n",
       "      <td>86099.876952</td>\n",
       "      <td>-0.049577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>246.0</td>\n",
       "      <td>-7.891140</td>\n",
       "      <td>11268.679387</td>\n",
       "      <td>0.303489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1128.5</td>\n",
       "      <td>56.176227</td>\n",
       "      <td>148112.626499</td>\n",
       "      <td>0.573022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1074.5</td>\n",
       "      <td>-2.815963</td>\n",
       "      <td>63062.828713</td>\n",
       "      <td>-0.110249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>707.0</td>\n",
       "      <td>-31.137662</td>\n",
       "      <td>72841.483124</td>\n",
       "      <td>0.698109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1672.5</td>\n",
       "      <td>-16.371735</td>\n",
       "      <td>244899.009726</td>\n",
       "      <td>-0.735545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>375.5</td>\n",
       "      <td>-13.025873</td>\n",
       "      <td>12030.419638</td>\n",
       "      <td>-0.147064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1343.5</td>\n",
       "      <td>-5.947034</td>\n",
       "      <td>188225.527827</td>\n",
       "      <td>-0.647590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1128.5</td>\n",
       "      <td>56.176227</td>\n",
       "      <td>148112.626499</td>\n",
       "      <td>0.573022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1672.5</td>\n",
       "      <td>-16.371735</td>\n",
       "      <td>244899.009726</td>\n",
       "      <td>-0.735545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1672.5</td>\n",
       "      <td>-16.371735</td>\n",
       "      <td>244899.009726</td>\n",
       "      <td>-0.735545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1023.0</td>\n",
       "      <td>-9.378814</td>\n",
       "      <td>53289.446932</td>\n",
       "      <td>0.114365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>527.5</td>\n",
       "      <td>-67.334147</td>\n",
       "      <td>35170.534916</td>\n",
       "      <td>0.425622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>707.0</td>\n",
       "      <td>-31.137662</td>\n",
       "      <td>72841.483124</td>\n",
       "      <td>0.698109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>852.5</td>\n",
       "      <td>-18.520137</td>\n",
       "      <td>123207.981594</td>\n",
       "      <td>-0.753019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>-21.550891</td>\n",
       "      <td>291865.435597</td>\n",
       "      <td>0.180866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.5</td>\n",
       "      <td>-4.132048</td>\n",
       "      <td>1633.048953</td>\n",
       "      <td>0.032805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102.0</td>\n",
       "      <td>-5.324628</td>\n",
       "      <td>754.237795</td>\n",
       "      <td>-0.281320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>132.0</td>\n",
       "      <td>1.684403</td>\n",
       "      <td>1334.384900</td>\n",
       "      <td>0.054414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>130.5</td>\n",
       "      <td>8.169880</td>\n",
       "      <td>1511.963330</td>\n",
       "      <td>0.008883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>130.5</td>\n",
       "      <td>8.169880</td>\n",
       "      <td>1511.963330</td>\n",
       "      <td>0.008883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>104.0</td>\n",
       "      <td>7.651208</td>\n",
       "      <td>974.495625</td>\n",
       "      <td>-0.047926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>155.5</td>\n",
       "      <td>6.127654</td>\n",
       "      <td>1800.605867</td>\n",
       "      <td>0.055195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>162.0</td>\n",
       "      <td>-13.334635</td>\n",
       "      <td>2139.935127</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.0</td>\n",
       "      <td>8.200879</td>\n",
       "      <td>990.880077</td>\n",
       "      <td>-0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.5</td>\n",
       "      <td>-13.600195</td>\n",
       "      <td>1475.830881</td>\n",
       "      <td>-0.120190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>105.0</td>\n",
       "      <td>8.664389</td>\n",
       "      <td>890.132666</td>\n",
       "      <td>0.050575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>112.0</td>\n",
       "      <td>-5.895289</td>\n",
       "      <td>845.370290</td>\n",
       "      <td>0.197725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104.5</td>\n",
       "      <td>-5.378570</td>\n",
       "      <td>865.928201</td>\n",
       "      <td>0.009344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>104.0</td>\n",
       "      <td>7.651208</td>\n",
       "      <td>974.495625</td>\n",
       "      <td>-0.047926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>184.0</td>\n",
       "      <td>5.012692</td>\n",
       "      <td>2220.598814</td>\n",
       "      <td>-0.195767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>184.0</td>\n",
       "      <td>5.012692</td>\n",
       "      <td>2220.598814</td>\n",
       "      <td>-0.195767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156.0</td>\n",
       "      <td>-27.369539</td>\n",
       "      <td>1909.717481</td>\n",
       "      <td>0.202650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>162.0</td>\n",
       "      <td>-13.334635</td>\n",
       "      <td>2139.935127</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165.0</td>\n",
       "      <td>12.705150</td>\n",
       "      <td>2222.631150</td>\n",
       "      <td>-0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165.0</td>\n",
       "      <td>12.705150</td>\n",
       "      <td>2222.631150</td>\n",
       "      <td>-0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>876.5</td>\n",
       "      <td>12.870393</td>\n",
       "      <td>110526.604876</td>\n",
       "      <td>-0.472757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>-21.550891</td>\n",
       "      <td>291865.435597</td>\n",
       "      <td>0.180866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1047.5</td>\n",
       "      <td>-2.402490</td>\n",
       "      <td>131905.577568</td>\n",
       "      <td>-0.755748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>563.0</td>\n",
       "      <td>10.474982</td>\n",
       "      <td>35506.141490</td>\n",
       "      <td>-0.024357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>852.5</td>\n",
       "      <td>-18.520137</td>\n",
       "      <td>123207.981594</td>\n",
       "      <td>-0.753019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>335.5</td>\n",
       "      <td>-53.463754</td>\n",
       "      <td>11322.854984</td>\n",
       "      <td>1.107440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature amplitude       mean       variance      skew\n",
       "channel         0          0              0         0\n",
       "476         984.5 -33.119112   86099.876952 -0.049577\n",
       "485         590.5  -5.672687   45599.431797  0.288864\n",
       "495         876.5  12.870393  110526.604876 -0.472757\n",
       "499        1396.0  47.100073  228947.748833 -1.347758\n",
       "4           170.0 -17.999268    2016.994142  0.142753\n",
       "3           171.5  -3.992433    2215.802969  0.063678\n",
       "6           162.0 -13.334635    2139.935127  0.003179\n",
       "10          149.5 -13.600195    1475.830881 -0.120190\n",
       "11          138.5 -14.408348    1567.651900 -0.091485\n",
       "7           126.5  -5.653893    1046.012990 -0.023597\n",
       "8           105.0   8.200879     990.880077 -0.002426\n",
       "12          109.0   7.406395    1063.600769  0.005112\n",
       "10          149.5 -13.600195    1475.830881 -0.120190\n",
       "10          149.5 -13.600195    1475.830881 -0.120190\n",
       "5           151.5 -27.823041    2027.044839  0.002501\n",
       "499        1396.0  47.100073  228947.748833 -1.347758\n",
       "489         945.5   3.282158   67213.825195  0.216552\n",
       "487        1464.0 -21.550891  291865.435597  0.180866\n",
       "476         984.5 -33.119112   86099.876952 -0.049577\n",
       "461         246.0  -7.891140   11268.679387  0.303489\n",
       "456        1128.5  56.176227  148112.626499  0.573022\n",
       "448        1074.5  -2.815963   63062.828713 -0.110249\n",
       "450         707.0 -31.137662   72841.483124  0.698109\n",
       "451        1672.5 -16.371735  244899.009726 -0.735545\n",
       "457         375.5 -13.025873   12030.419638 -0.147064\n",
       "459        1343.5  -5.947034  188225.527827 -0.647590\n",
       "456        1128.5  56.176227  148112.626499  0.573022\n",
       "451        1672.5 -16.371735  244899.009726 -0.735545\n",
       "451        1672.5 -16.371735  244899.009726 -0.735545\n",
       "447        1023.0  -9.378814   53289.446932  0.114365\n",
       "..            ...        ...            ...       ...\n",
       "430         527.5 -67.334147   35170.534916  0.425622\n",
       "450         707.0 -31.137662   72841.483124  0.698109\n",
       "467         852.5 -18.520137  123207.981594 -0.753019\n",
       "487        1464.0 -21.550891  291865.435597  0.180866\n",
       "0           143.5  -4.132048    1633.048953  0.032805\n",
       "14          102.0  -5.324628     754.237795 -0.281320\n",
       "23          132.0   1.684403    1334.384900  0.054414\n",
       "26          130.5   8.169880    1511.963330  0.008883\n",
       "26          130.5   8.169880    1511.963330  0.008883\n",
       "18          104.0   7.651208     974.495625 -0.047926\n",
       "13          155.5   6.127654    1800.605867  0.055195\n",
       "6           162.0 -13.334635    2139.935127  0.003179\n",
       "8           105.0   8.200879     990.880077 -0.002426\n",
       "10          149.5 -13.600195    1475.830881 -0.120190\n",
       "16          105.0   8.664389     890.132666  0.050575\n",
       "20          112.0  -5.895289     845.370290  0.197725\n",
       "21          104.5  -5.378570     865.928201  0.009344\n",
       "18          104.0   7.651208     974.495625 -0.047926\n",
       "15          184.0   5.012692    2220.598814 -0.195767\n",
       "15          184.0   5.012692    2220.598814 -0.195767\n",
       "9           156.0 -27.369539    1909.717481  0.202650\n",
       "6           162.0 -13.334635    2139.935127  0.003179\n",
       "2           165.0  12.705150    2222.631150 -0.004100\n",
       "2           165.0  12.705150    2222.631150 -0.004100\n",
       "495         876.5  12.870393  110526.604876 -0.472757\n",
       "487        1464.0 -21.550891  291865.435597  0.180866\n",
       "475        1047.5  -2.402490  131905.577568 -0.755748\n",
       "464         563.0  10.474982   35506.141490 -0.024357\n",
       "467         852.5 -18.520137  123207.981594 -0.753019\n",
       "468         335.5 -53.463754   11322.854984  1.107440\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fset_5.iloc[X_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-24., -15.,  -5., ..., -57., -54., -30.],\n",
       "       [-48., -52., -63., ...,  -5.,  -9.,   0.],\n",
       "       [ 49.,  54.,  62., ...,  12.,  13.,  40.],\n",
       "       ...,\n",
       "       [ 39.,  41.,  43., ..., -29., -16.,   1.],\n",
       "       [249., 218., 176., ..., 367., 299.,  26.],\n",
       "       [ 34.,  34.,  31., ...,  -7., -20.,  91.]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
